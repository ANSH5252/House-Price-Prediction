# ğŸ  House Prices - Advanced Regression Techniques  
This project presents a comprehensive solution to the House Prices: Advanced Regression Techniques competition on Kaggle. The goal is to predict the final price of residential homes in Ames, Iowa using advanced machine learning models and feature engineering.

## ğŸ“‚ Repository Structure
```
House-Prices-Advanced-Regression-Techniques/
â”‚
â”œâ”€â”€ data_description.txt     # Info About the Features of Dataset
â”œâ”€â”€ h_p_p.ipynb              # Jupyter notebooks for EDA, modeling, and evaluation
â”œâ”€â”€ train.csv                # Dataset for Training Puropse
â”œâ”€â”€ test.csv                 # Dataset for Test Puropse
â”œâ”€â”€ sample_submission.csv    # Format of Submission
â””â”€â”€ README.md                # Project documentation
```
##ğŸš€ Project Highlights
- ğŸ“Š **Exploratory Data Analysis (EDA) to understand distributions, relationships, and outliers

- ğŸ› ï¸ Feature Engineering including skewness handling, missing value treatment, and encoding

### ğŸ“‰ **Modeling Techniques:**

- ğŸ”¹ **Linear Models:**
  - Linear Regression
  - Ridge Regression
  - Lasso / ElasticNet

- ğŸŒ³ **Ensemble Models:**
  - Random Forest Regressor
  - XGBoost Regressor

- ğŸ§  **Neural Networks:**
  - MLPRegressor (Multi-layer Perceptron)

- ğŸ§± **Stacking Ensemble:**
  - StackingRegressor with meta-learners:
    - MLP
    - XGBoost
    - Linear Regression

- âš™ï¸ **Pipelines & Preprocessing:**
  - ColumnTransformer
  - Pipelines with OneHotEncoder, StandardScaler, SimpleImputer

- ğŸ” **Model Selection:**
  - GridSearchCV for hyperparameter tuning
  - K-Fold Cross-Validation

- ğŸ“‰ **Evaluation Metrics:**
  - RMSE (Root Mean Squared Error)


## ğŸ“Œ Key Techniques Used

- ğŸ“Š **Exploratory Data Analysis (EDA)**  
  - SalePrice distribution analysis  
  - Q-Q plots and normality checks  
  - Outlier detection using **IQR method**

- ğŸ§¹ **Data Preprocessing**
  - Missing value imputation using `SimpleImputer`
  - Feature scaling with `StandardScaler`
  - Categorical encoding with `OneHotEncoder`
  - Feature pipelines using `ColumnTransformer` and `Pipeline`

- ğŸ§  **Feature Engineering**
  - Log transformation of skewed features  
  - PCA for dimensionality reduction *(if applied)*  
  - Manual selection of important features

- ğŸ“¦ **Model Training & Evaluation**
  - Training multiple models with `GridSearchCV`
  - Hyperparameter tuning with exhaustive search
  - Cross-validation using `KFold`
  - Evaluation using **Root Mean Squared Error (RMSE)**

- ğŸ§± **Ensemble Learning**
  - Combining models using `StackingRegressor` with multiple meta-models  
  - Meta-model tuning (MLP, XGBoost, LinearRegression)

- ğŸ“ˆ **Visualization**
  - Interactive plots using **Plotly** (`plotly.express`, `go.Figure`)
  - Histogram + Normal distribution overlay
  - Q-Q plots for assessing normality



## ğŸ‘¤ Author
Anshuman Dash  
[![GitHub](https://img.shields.io/badge/GitHub-Profile-black?logo=github)](https://github.com/ANSH5252)

## ğŸ“œ License
This project is licensed under the MIT License.     

